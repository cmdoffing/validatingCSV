## validatingCSV: A Declarative, Validating CSV Reader Library For Python 3

### Overview

validatingCSV is a Python package for inputting and converting data from CSV iterables.
Use validatingCSV when your CSV data absolutely, positively has to be valid.
Which is pretty much always.

### Design Goals

validatingCSV has the following design goals:

* Maximum input validation. This is based on this developer's long experience with
data conversion, where the main lesson has been that
that bad input data is far more common that is usually supposed. We want to check the
input data in every way possible.

* Declarative specification. In general, declarative code has fewer bugs and is easier
to modify than functional, OOP, or imperative code. Let's do more of this.

* In particular, input validation should be as declarative as possible, even though validation
sometimes requires functional code. No OOP or imperative code should ever be necessary.

* It must be possible to specify more than one validator for each field.
This makes it easier to clarify intent, since each validator is doing exactly one (small) thing.
Validation for a field, but not a row, should
stop immediately after the first validation failure, since spurious and confusing error
messages may be generated due to the preconditions of later validators not holding.

* Validation error messages should include the erroneous CSV row as well as all error
messages from all validators. These should be written to a text (utf-8) file if a path
for an error file is specified. It should also be easy to additionally write them to stderr.

* It should be possible to generate named tuples easily with the names supplied by
the user in the input specification.

### Trade-offs

Since validatingCSV does everything the built-in csv module does and a lot more, it is naturally
going to be slower. This is a more than acceptable trade-off in most contexts, since getting
the wrong answer quickly isn't very useful. Programming is ultimately about data, and bad
data is worse than no data, especially when you don't know it's bad.

### How It Works

```python
import validatingCSV as vcsv

validationParams = {...}
with open('spam.csv', newline='') as csvfile:
    spamreader = vcsv.reader(csvfile, validationParams)
    for row in spamreader:
        print()
```

### CSV Iterable API

Fully specifying a validatingCSV reader requires defining two dicts: one for the
CSV file or other iterable as a whole and one for the fields in the rows.
This section defines the CSV iterable as a whole.
The Field Specification API further below describes how fields should be defined.

The validatingCSV reader uses Python's built-in csv module to perform reader 
operations on csv iterables. To do this, the validatingCSV module supplies any
parameters needed by the standard csv reader. Unsurprisingly then, the
CSV Iterable API precisely mirrors that of the Dialect class supplied to the
csv reader.

To specify parameters for the CSV iterable, define a dict that contains entries for
any of the parameters that need to be supplied to the csv reader, as defined in
the [documentation for the Dialect class](https://docs.python.org/3/library/csv.html#csv-fmt-params).
What follows is a repetition of the information found there, put here for convenience.

* 'fields' : Required. A sequence of field definitions (see Field Specification API below).
These tell the validatingCSV reader which fields in a row are to be processed and how they
are to be validated and/or converted.

* 'delimiter' : A one-character string used to separate fields. It defaults to ','.

* 'doublequote' : Controls how instances of quotechar appearing inside a field should themselves be quoted. When True, the character is doubled. When False, the escapechar is used as a prefix to the quotechar. It defaults to True.

  * On output, if doublequote is False and no escapechar is set, Error is raised if a quotechar is found in a field.

* 'escapechar' : A one-character string used by the writer to escape the delimiter if quoting is set to QUOTE_NONE and the quotechar if doublequote is False. On reading, the escapechar removes any special meaning from the following character. It defaults to None, which disables escaping.

* 'lineterminator' : The string used to terminate lines produced by the writer. It defaults to '\r\n'. Note The reader is hard-coded to recognize either '\r' or '\n' as end-of-line, and ignores lineterminator. This behavior may change in the future.

* 'quotechar' : A one-character string used to quote fields containing special characters, such as the delimiter or quotechar, or which contain new-line characters. It defaults to '"'.

* 'quoting' : Controls when quotes should be generated by the writer and recognised by the reader. It can take on any of the QUOTE_* constants (see section Module Contents) and defaults to QUOTE_MINIMAL.

* 'skipinitialspace' : When True, whitespace immediately following the delimiter is ignored. The default is False.

* 'strict' : When True, raise exception Error on bad CSV input. The default is False.


#### Field Specification API

Every row in a CSV iterable (except possibly the headers) has (or should have) the same number of fields.
While the CSV Iterable API defines the parameters for the file or stream as a whole,
the row API allows you to define a name, validators, and data converters for each field.

A row specification consists of a sequence of field specifications, with exactly one specification for each field in the row.

If the rows have fields at the end that you want to ignore, you can forgo specifying
field validations for these. They will be ignored.

Since the API uses dictionaries to specify the fields, it is useful to check to make sure the 
keys and their values are all accurate. All of the following attributes are optional
except for 'name.'

Frequently, you will want to ignore the values from a given field.
To handle this case, place a falsy value (None is recommended) in the field specification.
The field will be ignored in all rows, saving processing time.

There are several kinds of validations that can be specified. They are done in the order
listed below. If any one of them fails, no further validations are done for that field
in the current row.

* 'name' : Every field spec should define a 'name' entry.
This will be used to create the field's name in the named tuple representing the row.
The name must be a valid Python identifier.

* 'desc' : A string describing the field. Useful for program documentation. Defaults to
empty string if missing or the value is falsy.

* 'type' : If present, this must be either a falsy value, in which case the field
will be typed as a string, or one of str, int, float, complex, or ord
(without enclosing in quotes).
If not present or falsy, this defaults to str and no check is done on the type of the field's
contents, since all fields are read in as strings. This is also true if you specify 'type': str.
Forgoing a type check saves time.
If the type is ord, the Unicode integer code point of the character is returned.

* 'default' : The default value to return if the field is empty. This default will be checked
against the type and an exception will be raised if they are not consistent.

* 'base' : The base (radix) to by the int(num, base) function for integer conversions.
This must be either missing, falsy, or one of the legal values for the base parameter.
These are 2 - 36.
If this is present when the 'type' entry is missing, falsy or not int,
an exception will be thrown. If the base is not a valid value, an exception is thrown.
If present when 'type' == int and the base is valid, the field is converted to an
integer using this base.

* 'min' : The minimum value of the field. This can be an integer, a float, a complex number,
or a string. The standard Python comparison operator is used.

* 'max' : The maximum value of a field. Similar considerations as for 'min'.

* 'valid_values' : An iterable containing only those values that are valid for this field.
If this is present and either 'min' or 'max' is present and truthy, an exception is thrown.
If a non-string type is used, the field will first be converted to a value of that type
before this check is made.
Strings types are checked directly against the values here.
All values in this field will be checked against the 'type' entry and an exception
will be thrown if there is a mismatch.
When enumerating valid values, a frozenset is recommended.

* 'error_checker' : A user-defined function that is called with two parameters:
the original (string)
value of the field as the first parameter and the converted value (if a non-string
'type' entry is present) is the second. This is to avoid doing the conversion
twice in some cases, saving time.
Note that, if present, 'min', 'max', and/or 'valid_values' checks will be done before
this is called.
If no conversion has been done, then the second parameter will be None.
Return the error message as a string if there is an error, else return a falsy value.

* 'converter' : A user-defined function that is called with a single parameter:
the original (string) value of the field. It returns the converted value of the field,
which is then passed to the caller as the field's value.
